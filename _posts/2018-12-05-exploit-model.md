---
layout: post
title: Discussing Exploitation and Priv Escalation - Analysis of gVisor exploit
date: 2018-12-05
author: lumjjb
description: Discussing Exploitation and Priv Escalation - Analysis of gVisor exploit
---

In this blog post, we take a look at the work that Max Justicz wrote about in his post ["Privilege Escalation in gVisor, Google's Container Sandbox"](https://justi.cz/security/2018/11/14/gVisor-lpe.html). We discuss the threat model of gVisor and what the exploit provides and the differences between the LibOS security model between gVisor and Nabla containers. Finally, we explore some other threats.

## Exploitation 102: Attacker capabilities

To understand a few concepts that we would like to talk about, let us go into a quick primer on how exploits are written. There are multiple reasons why an attacker would like to exploit an application. The most common reasons are that they want to leak some data from the application, or they want to be able to execute arbitrary code in the application (code exec).

Let's assume that we are exploiting an application (this could be something like redis or nginx) and we want to achieve arbitrary code execution (code exec).

Starting with our goal, we want to describe how an attacker derives an exploit - arbitrary code execution. How do we get arbitrary code execution? One way of doing that is by hijacking the control flow of the application. This can be done via various methods, like overwriting function pointers, overwriting an entry in the `.got` (Global Offset Table entries contain function pointers of dynamically linked libraries), or taking advantage of architecture specific behaviors (like overwriting the return address in the stack used by the `ret` instruction), etc.

The main way of figuring out how to do this is by reverse engineering the application binary and finding bugs in the application. For example, a failure to check bounds may lead to a leak of stack data or heap data ([Heartbleed](http://heartbleed.com/)). And a use after free bug in memory allocation may be able to provide the ability to write to an arbitrary memory address. 

These type of bugs are too varied to identify and classify, which is why one way that we may think about them as *attacker capabilities* - what a bug gives us. For example, a use after free bug may provide us with an arbitrary write to any memory address (we call arb write for short), and the ability to leak some address information, we call a leak. 

These usually give us the ability to exploit more bugs - by learning about the location of data structures and code pages, or by triggering code paths originally not reachable. For example, a leak counters [Address Space Layout Randomization (ASLR)](https://en.wikipedia.org/wiki/Address_space_layout_randomization)  by showing us the significant bits of the randomized address space. The ability to read pointers of two libc functions lets us derive the version of libc being used. The list goes on...

In general, with attacker capabilities to leak and arb write, it is almost a guarantee that we can get the capability to code exec. However, sometimes, we may only get limited versions of these capabilities. For example, instead of arb read/write, we could only have limited read/write to a certain memory region.

Other examples of these are unreliable read/writes (does not always happen, depending on some randomness of the program), or read/writes that can include randomness or proximity. However, these type of limited capabilities can be overcome with additional work - performing actions more than once (rowhammer) or using certain techniques (i.e. heap spraying, nop slides).

## Explaining "Prvilege Escalation in gVisor"

```
+--------+ +--------+   +---------+
|  p1a   | |  p1a   |   |   p2a   |                      APP
+--------+ +--------+   +---------+
+-------------------+   +-------------------+
|      gVisor       |   |      gVisor       |            gVisor
+-------------------+   +-------------------+
+--------------------------------------------------+
|                    kernel                        |     KERNEL
+--------------------------------------------------+
```

Before we jump into the exploit, let us look at how gVisor is used. Instances of gVisor can be created independent of each other with a shared kernel. For each gVisor instance, there can be one or more application processes running on them (i.e. `p1a`, `p1b`).

Now, let's take a look at [Max's work with gVisor](https://justi.cz/security/2018/11/14/gVisor-lpe.html). In his blog, he explains the bug that he has found in the gVisor implementation of the `shmctl` syscall, and an example of how he is able to perform targeted writes to a seperate process using the same gVisor userspace kernel.

The exploit assumes the following attacker capabilities: Code exec in an application process. This can be obtained via exploitation of the process `p1a` (i.e. redis/nginx). We annotate the diagram with attacker capabilities assumed in parentheses.

```
+--------+ +--------+   +---------+
|  p1a   | |  p1b   |   |   p2a   |                      APP
| (code) | |        |   |         |                      
| (exec) | |        |   |         |                      
+--------+ +--------+   +---------+
+-------------------+   +-------------------+
|      gVisor       |   |      gVisor       |            gVisor
+-------------------+   +-------------------+
+--------------------------------------------------+
|                    kernel                        |     KERNEL
+--------------------------------------------------+
```

The exploit abuses the `shmctl` bug to acheive the attacker capabilities to perform limited write to select memory region of which gVisor has access to. Max then uses this limited write capability to show that he has obtained capability of random writes to the adjacent application process `p1b`, by attempting to write 'A's (`0x41`) to the specific region/pages exposed by the bug.

```
    +---WRITE--+
    |          |
    |          V
+--------+ +--------+   +---------+
|  p1a   | |  p1b   |   |   p2a   |                      APP
| (code) | |(random)|   |         |                      
| (exec) | |( write)|   |         |                      
+--------+ +--------+   +---------+
+-------------------+   +-------------------+
|      gVisor       |   |      gVisor       |            gVisor
|  (limited write)  |   |                   |            
+-------------------+   +-------------------+
+--------------------------------------------------+
|                    kernel                        |     KERNEL
+--------------------------------------------------+
```

### Safe for now

This proof of concept has shown random writes into an adjacent process on the same instance of gVisor. However, we note that to get the most out of gVisor isolation, one would want to have each process be on seperate gVisor instances. Thus, there is no reason to panic today, based on this proof of concept alone.

### Other implications

This is one of many direction that Max has taken to build up his exploit - by showing random write into a adjacent application sharing the same gVisor instance. However, he mentions that for the limited write region in this bug:

>The backing memory is then reclaimed and handed to another (potentially more privileged) process.

This may perhaps lead to possibilities to obtain more attacker capabilities in the gVisor instance - maybe even code exec? We'll discuss this next.


## Exploring differences in LibOS security model

Let's dive a little deeper into a hypothetical scenario where an attacker obtains code exec capabilities in gvisor. So assuming that we are able to exploit and get code exec in gVisor, what protections do we get in terms of isolation? 

Syscalls are the way that an application interfaces with gVisor, and we can view it as an estimation of the attack surface[^1] from the application to gVisor. We've seen here that the exposure of 300+ syscalls consists of `shmctl`, which allowed the application process to trigger a bug in gVisor.

So assuming that we've obtained code exec in gVisor, what is our exposure? We looked at the [seccomp policy of gVisor](https://github.com/google/gVisor/blob/0091db9cbddb6c9fb4c96fbde980780c98006eda/runsc/boot/filter/config.go), and it is assuring to see that the seccomp policy only allows 83 or the 300+ syscalls available. Therefore, given an exploit in the gVisor kernel, the attack surface is much reduced compared to regular containers.

```
+--------+              +---------+
|  p1a   |              |   p2a   |                      APP
+--------+              +---------+
<<< 300 syscalls  >>>   <<< 300 syscalls  >>>
+-------------------+   +-------------------+
|      gVisor       |   |      gVisor       |            gVisor
|   (code exec)     |   |                   |            
+-------------------+   +-------------------+
<<<  83 syscalls  >>>   <<<  83 syscalls  >>>     <--- Attack surface 
+--------------------------------------------------+
|                    kernel                        |     KERNEL
+--------------------------------------------------+
```

Based on this, in order to break isolation between gVisor instances, an attacker would need to obtain code exec or something similar in the kernel via the 83 syscalls allowed.



### Another model: LibOS with Nabla

Let's compare the Nabla containers model with that of gVisor. The components are very similar, gVisor is a userspace kernel, and Nabla has a Library OS (LibOS). This LibOS does a similar function - implementing the functionality of the kernel in userspace and only calling the host kernel when necessary. 

Right now, we don't distinguish between the application and the LibOS, and we treat the LibOS as untrusted. For the application and LibOS, we have a seccomp policy that only allows 7 syscalls, with only two file descriptions (a block device and tap device).

```
+--------+              +---------+
|  p1a   |              |   p2a   |                      APP
+-------------------+   +-------------------+
|    nabla LibOS    |   |   nabla LibOS     |            LibOS
|    (code exec)    |   |                   |            
+-------------------+   +-------------------+
<<<   7 syscalls  >>>   <<<   7 syscalls  >>>     <--- Attack surface 
+--------------------------------------------------+
|                    kernel                        |     KERNEL
+--------------------------------------------------+
```

For nabla, the attack surface to obtain code exec in the kernel would need to be from these 7 syscalls.



To summarize, here's a side-by-side comparison of the models:

```
      gVisor                   NABLA
      ------                   -----

+--------+              
|  p1a   |                                              APP
+--------+              +---------+
<<< 300 syscalls  >>>   |   p2a   |          
+-------------------+   +-------------------+
|      gVisor       |   |   nabla LibOS     |           LibOS
|   (code exec)     |   |                   |            
+-------------------+   +-------------------+
<<<  83 syscalls  >>>   <<<   7 syscalls  >>>     <--- Attack surface 
+--------------------------------------------------+
|                    kernel                        |     KERNEL
+--------------------------------------------------+
```


We note a subtle difference in the way the application links to the LibOS. In gVisor, the LibOS acts as an additional protection boundary which guards[^2] against the inputs that can be invoked with the 83 syscalls.


## But it's a memory safe langauge!

Some argue that gVisor is written in golang, and therefore memory safe. Golang is safer, but is not immune to the same class of bugs that we've discussed in this post.

I believe that golang is a safer language from the programming language standpoint (i.e. the common design pattern doesn't allow writing to arbitrary pointers and performing malloc/free operations), but it is hard to guarantee that the implementation is true to the language semantics. Often, bugs in implementation or performance trade-offs (this is rampant in the hardware work with [Spectre](https://meltdownattack.com/) variant bugs) are the result of this.

As a bonus, here are two implementations of memory corruption POCs - one from an implementation bug, and one from a performance design standpoint.

### Implementation bug

The security research and CTF group that I am part of, [Plaid Parliament of Pwning (PPP)](https://pwning.net/), worked on showing a memory corruption attack leading to code exec in the golang playground. You may view the blog post by Alex Reece [here](http://codearcana.com/posts/2013/04/23/exploiting-a-go-binary.html).

### Design bug

The bug here is due a data race of some data types using multiword values (i.e. a type is represented by multiple words in byte) and a race in the garbage collector. 

The vulnerability is detailed on STALKR's blog post ["Golang data races to break memory safety"](https://blog.stalkr.net/2015/04/golang-data-races-to-break-memory-safety.html) and discussion on the design and trade-offs are talked about in [Russ Cox's blogpost](https://research.swtch.com/gorace).

## What's next?

In conclusion, we've observed that gVisor and Nabla draw several similarities in the threat model, and yet they focus on different methods of providing security - maximum attack surface reduction (Nabla) vs additional protection boundaries (gVisor). We hope to see more interesting proof of concepts like Max's to help us continue to fine tune our isolation threat model!

P.S. We think that the separation of protection boundaries between the application and the LibOS performed by gVisor is a good thing to have, at least in terms of address space separation - and this is something we may look into in the future!

[^1]: [Refining the Isolation Metric]({% post_url 2018-08-03-metrics %})
[^2]: The guarding is implicit in a way that the logic of the implementation would constrain the total number of syscalls invokable by a well behaved gVisor. One analogy of this is that by providing an interface of a TCP socket, we gaurd an application against writing malformed packets to the network.
